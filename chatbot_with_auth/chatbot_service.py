# chatbot_service.py

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

from config import settings

# CHANGE: The function is now a generator, so its return type hint is removed.
# It will 'yield' chunks of text as they are generated by the AI.
def get_chatbot_response(prompt: str):
    """
    Initializes the chatbot model and gets a streaming response.
    Args:
        prompt: The message from the user.
    Yields:
        str: Chunks of the bot's response.
    """
    if not settings.google_api_key:
        raise ValueError("GOOGLE_API_KEY is not set in the environment.")

    llm = ChatGoogleGenerativeAI(model="models/gemini-2.5-flash-lite", google_api_key=settings.google_api_key)
    
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", (
            "You are a helpful assistant. Format your responses using GitHub-flavored Markdown. "
            "Use code blocks with language identifiers for all code snippets (e.g., ```python). "
            "Use bold and italics for emphasis. Use bullet points for lists."
        )),
        ("user", "{input}")
    ])
    
    output_parser = StrOutputParser()
    
    chain = prompt_template | llm | output_parser
    
    try:
        # DEBUG: Print the user message being sent to the AI
        print(f"--- DEBUG: Streaming from LangChain with prompt: '{prompt}' ---")

        # CHANGE: Instead of 'invoke', we use 'stream'.
        # This returns a generator that we can iterate over for real-time responses.
        response_stream = chain.stream({"input": prompt})

        # CHANGE: Iterate through the stream and yield each part
        for chunk in response_stream:
            # DEBUG: Print each chunk received from the AI before sending it
            print(f"--- DEBUG: AI CHUNK: {chunk}")
            yield chunk

    except Exception as e:
        # DEBUG: Print any errors that occur during the streaming process.
        print(f"--- DEBUG: Error streaming from LangChain: {e}")
        # CHANGE: If there's an error, yield a user-friendly error message.
        yield "Sorry, I encountered an error while processing your request."

